{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a262698b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved to locations_cleaned.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5x/s2s7fh3n7217xs1bjv8kyc8m0000gn/T/ipykernel_2241/2665219838.py:25: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df = df[~df['Location'].str.contains(r'\\b(et al\\.|et al)\\b', case=False, regex=True)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to clean locations\n",
    "def clean_location(location):\n",
    "    # Remove leading and trailing whitespaces\n",
    "    location = location.strip()\n",
    "\n",
    "    # Remove special characters\n",
    "    location = re.sub(r'[^a-zA-Z\\s]', '', location)\n",
    "\n",
    "    # Remove numbers\n",
    "    location = re.sub(r'\\d', '', location)\n",
    "\n",
    "    return location\n",
    "\n",
    "# Read Excel file\n",
    "file_path = 'locations.xlsx'\n",
    "df = pd.read_excel(file_path, header=None, names=['Location'])\n",
    "\n",
    "# Clean locations column\n",
    "df['Location'] = df['Location'].apply(clean_location)\n",
    "\n",
    "# Remove rows where 'et al.' exists alone or as part of a phrase\n",
    "df = df[~df['Location'].str.contains(r'\\b(et al\\.|et al)\\b', case=False, regex=True)]\n",
    "\n",
    "# Remove rows where the cleaned 'Location' starts with 'doi'\n",
    "df = df[~df['Location'].str.lower().str.startswith('doi')]\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(subset=['Location'], keep='first', inplace=True)\n",
    "\n",
    "# Save cleaned data to a new Excel file\n",
    "output_file_path = 'locations_cleaned.xlsx'\n",
    "df.to_excel(output_file_path, index=False, header=True)\n",
    "\n",
    "print(f'Data cleaned and saved to {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469283cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Excel file\n",
    "file_path = 'locations.xlsx'\n",
    "df = pd.read_excel(file_path, header=None, names=['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba28dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = df['Location'].str.lower()\n",
    "df.drop_duplicates(subset=['Location'], keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d23216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data to a new Excel file\n",
    "output_file_path = 'locations_cleaned.xlsx'\n",
    "df.to_excel(output_file_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7b826fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df383085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Findings for Keyphrases_aws.xlsx:\n",
      "Total Keywords: 20872\n",
      "Locations Matched: 315\n",
      "Percentage Match: 1.51%\n",
      "Matched Locations: ['adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'adaptation', 'vietnam', 'urban', 'urban', 'nz', 'sea', 'change', 'change', 'change', 'change', 'change', 'scope', 'scope', 'scope', 'scope', 'scope', 'scope', 'ihme', 'ihme', 'ihme', 'ihme', 'botswana', 'australasia', 'australasia', 'australasia', 'magnan', 'malaria', 'malaria', 'malaria', 'kakumanu', 'kakumanu', 'australia', 'reynolds', 'reynolds', 'ar5', 'ar5', 'ar5', 'ar5', 'ar5', 'ar5', 'ar5', 'sovacool', 'gleick', 'gleick', 'usa', 'greenland', 'ticktin', 'ofoegbu', 'sm16.4', 'sm16.4', 'kattumuri', 'yegbemey', 'hallegatte', 'nienhuis', 'neset', 'persson', 'fuss et al.', 'north', 'north', 'north', 'samoa', 'gosling', 'gosling', 'kihila', 'kihila', 'sm16.5', 'riddle et al.', 'robalino et al.', 'tanoue et al.', 'icrc', 'klomp', 'duvat et al.', 'kelley et al.', 'rose et al.', 'rose et al.', 'rode et al.', 'jamaica', 'zhao et al.', 'hinkel et al.', 'chimhowu', 'pindyck', 'betzold', 'cropper et al.', 'cropper et al.', 'cropper et al.', 'zhan et al.', 'mainardi', 'mainardi', 'olmstead', 'elagib', 'hooli', 'wijenayake et al.', 'bose', 'postigo', 'baarsch et al.', 'debray et al.', 'abatayo et al.', 'kerr', 'sm16.6', 'merkens et al.', 'weaver et al.', 'vanuatu', 'koubi', 'tompkins et al.', 'burton', 'nuttall', 'mosquitos', 'fraga et al.', 'kelman', 'nordhaus', 'mazdiyasni', 'al.', 'al.', 'al.', 'jalles', 'mycoo', 'hauer']\n",
      "\n",
      "Findings for Keyphrases_tf-idf.xlsx:\n",
      "Total Keywords: 93516\n",
      "Locations Matched: 41\n",
      "Percentage Match: 0.04%\n",
      "Matched Locations: ['south africa', 'new york', 'united states', 'washington dc', 'small island states', 'southern africa', 'west africa', 'solomon islands', 'tanoue et al', 'kemper et', 'new zealand', 'van oldenborgh', 'east africa', 'palo alto', 'marshall islands', 'cape town', 'sri lanka', 'environ manage', 'north africa', 'sapkota et al', 'chumphon province', 'torres strait', 'costa rica', 'northwest costa rica', 'viet nam', 'addis abba', 'limpopo province', 'thulamela municipality', 'chitral pakistan', 'western uzbekistan', 'savanna systems', 'beiler et al', 'new york state', 'dar es salaam', 'henan province', 'de la sota', 'northwest territories', 'yunnan province', 'veronika huber', 'tabea lissner', 'boigu island']\n",
      "\n",
      "Findings for Keyphrases_yake.xlsx:\n",
      "Total Keywords: 50\n",
      "Locations Matched: 2\n",
      "Percentage Match: 4.00%\n",
      "Matched Locations: ['adaptation', 'change']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read cleaned locations file\n",
    "locations_df = pd.read_excel('locations_cleaned.xlsx', header=None, names=['Location'])\n",
    "\n",
    "# List of other Excel files\n",
    "keyword_files = ['Keyphrases_aws.xlsx', 'Keyphrases_tf-idf.xlsx', 'Keyphrases_yake.xlsx']\n",
    "\n",
    "# Dictionary to store findings\n",
    "findings = {}\n",
    "\n",
    "# Iterate through each keyword file\n",
    "for keyword_file in keyword_files:\n",
    "    # Read keyword file\n",
    "    keyword_df = pd.read_excel(keyword_file)\n",
    "\n",
    "    # Convert columns to lowercase for case-insensitive comparison\n",
    "    keyword_df['Keyword'] = keyword_df['Keyword'].str.lower()\n",
    "    locations_df['Location'] = locations_df['Location'].str.lower()\n",
    "\n",
    "    # Merge the cleaned locations with the keywords on 'Location'\n",
    "    merged_df = pd.merge(keyword_df, locations_df, how='inner', left_on='Keyword', right_on='Location')\n",
    "\n",
    "    # Extract matched locations\n",
    "    matched_locations = merged_df['Location'].tolist()\n",
    "\n",
    "    # Calculate the percentage of locations in each keyword file\n",
    "    percentage = (len(matched_locations) / len(keyword_df)) * 100\n",
    "\n",
    "    # Store findings in the dictionary\n",
    "    findings[keyword_file] = {\n",
    "        'Total Keywords': len(keyword_df),\n",
    "        'Locations Matched': len(matched_locations),\n",
    "        'Percentage Match': percentage,\n",
    "        'Matched Locations': matched_locations\n",
    "    }\n",
    "\n",
    "# Print the findings\n",
    "for keyword_file, result in findings.items():\n",
    "    print(f'Findings for {keyword_file}:')\n",
    "    print(f'Total Keywords: {result[\"Total Keywords\"]}')\n",
    "    print(f'Locations Matched: {result[\"Locations Matched\"]}')\n",
    "    print(f'Percentage Match: {result[\"Percentage Match\"]:.2f}%')\n",
    "    print(f'Matched Locations: {result[\"Matched Locations\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40e3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "#fuzzy all\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Read cleaned locations file\n",
    "locations_df = pd.read_excel('locations_cleaned.xlsx', header=None, names=['Location'])\n",
    "\n",
    "# List of other Excel files\n",
    "keyword_files = ['Keyphrases_aws.xlsx', 'Keyphrases_tf-idf.xlsx', 'Keyphrases_yake.xlsx']\n",
    "\n",
    "# Dictionary to store findings\n",
    "findings = {}\n",
    "\n",
    "# Fuzzy matching threshold (adjust as needed)\n",
    "threshold = 95\n",
    "\n",
    "# Iterate through each keyword file\n",
    "for keyword_file in keyword_files:\n",
    "    # Read keyword file\n",
    "    keyword_df = pd.read_excel(keyword_file)\n",
    "\n",
    "    # Convert columns to lowercase for case-insensitive comparison\n",
    "    keyword_df['Keyword'] = keyword_df['Keyword'].str.lower()\n",
    "    locations_df['Location'] = locations_df['Location'].str.lower()\n",
    "\n",
    "    # Dictionary to store matched locations\n",
    "    matched_locations_dict = {}\n",
    "\n",
    "    # Iterate through each keyword\n",
    "    for keyword in keyword_df['Keyword']:\n",
    "        # Use fuzzywuzzy process to find the best match\n",
    "        match, score, index = process.extractOne(keyword, locations_df['Location'])\n",
    "        \n",
    "        # Check if the match meets the threshold\n",
    "        if score >= threshold:\n",
    "            # Store the matched location\n",
    "            matched_locations_dict[keyword] = match\n",
    "\n",
    "    # Calculate the percentage of locations in each keyword file\n",
    "    percentage = (len(matched_locations_dict) / len(keyword_df)) * 100\n",
    "\n",
    "    # Store findings in the dictionary\n",
    "    findings[keyword_file] = {\n",
    "        'Total Keywords': len(keyword_df),\n",
    "        'Locations Matched': len(matched_locations_dict),\n",
    "        'Percentage Match': percentage,\n",
    "        'Matched Locations': matched_locations_dict\n",
    "    }\n",
    "\n",
    "# Print the findings\n",
    "for keyword_file, result in findings.items():\n",
    "    print(f'Findings for {keyword_file}:')\n",
    "    print(f'Total Keywords: {result[\"Total Keywords\"]}')\n",
    "    print(f'Locations Matched: {result[\"Locations Matched\"]}')\n",
    "    print(f'Percentage Match: {result[\"Percentage Match\"]:.2f}%')\n",
    "    print(f'Matched Locations: {result[\"Matched Locations\"]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Read cleaned locations file\n",
    "locations_df = pd.read_excel('locations_cleaned.xlsx', header=None, names=['Location'])\n",
    "\n",
    "# List of other Excel files\n",
    "keyword_files = ['Keyphrases_aws.xlsx', 'Keyphrases_td-idf.xlsx', 'Keyphrases_yake.xlsx']\n",
    "\n",
    "# Dictionary to store findings\n",
    "findings = {}\n",
    "\n",
    "# Fuzzy matching threshold (adjust as needed)\n",
    "threshold = 90\n",
    "\n",
    "# Iterate through each keyword file\n",
    "for keyword_file in keyword_files:\n",
    "    # Read keyword file\n",
    "    keyword_df = pd.read_excel(keyword_file)\n",
    "\n",
    "    # Convert columns to lowercase for case-insensitive comparison\n",
    "    keyword_df['Keyword'] = keyword_df['Keyword'].str.lower()\n",
    "    locations_df['Location'] = locations_df['Location'].str.lower()\n",
    "\n",
    "    # Dictionary to store matched locations\n",
    "    matched_locations_dict = {}\n",
    "\n",
    "    # Iterate through each keyword\n",
    "    for keyword in keyword_df['Keyword']:\n",
    "        # Use fuzzywuzzy process to find the best match\n",
    "        match = process.extractOne(keyword, locations_df['Location'])\n",
    "        \n",
    "        # Check if the match meets the threshold\n",
    "        if match[1] >= threshold:\n",
    "            # Store the matched location\n",
    "            matched_locations_dict[keyword] = match[0]\n",
    "\n",
    "    # Calculate the percentage of locations in each keyword file\n",
    "    percentage = (len(matched_locations_dict) / len(keyword_df)) * 100\n",
    "\n",
    "    # Store findings in the dictionary\n",
    "    findings[keyword_file] = {\n",
    "        'Total Keywords': len(keyword_df),\n",
    "        'Locations Matched': len(matched_locations_dict),\n",
    "        'Percentage Match': percentage,\n",
    "        'Matched Locations': matched_locations_dict\n",
    "    }\n",
    "\n",
    "# Print the findings\n",
    "for keyword_file, result in findings.items():\n",
    "    print(f'Findings for {keyword_file}:')\n",
    "    print(f'Total Keywords: {result[\"Total Keywords\"]}')\n",
    "    print(f'Locations Matched: {result[\"Locations Matched\"]}')\n",
    "    print(f'Percentage Match: {result[\"Percentage Match\"]:.2f}%')\n",
    "    print(f'Matched Locations: {result[\"Matched Locations\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove spaces, special characters, numbers, commas, points, etc.\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z]', '', str(text))\n",
    "    return cleaned_text\n",
    "\n",
    "# Read cleaned locations file\n",
    "locations_df = pd.read_excel('locations_cleaned.xlsx', header=None, names=['Location'])\n",
    "locations_df['Location'] = locations_df['Location'].apply(clean_text)\n",
    "\n",
    "# List of other Excel files\n",
    "keyword_files = ['Keyphrases_aws.xlsx', 'Keyphrases_td-idf.xlsx', 'Keyphrases_yake.xlsx']\n",
    "\n",
    "# Dictionary to store findings\n",
    "findings = {}\n",
    "\n",
    "# Fuzzy matching threshold (adjust as needed)\n",
    "threshold = 92\n",
    "\n",
    "# Iterate through each keyword file\n",
    "for keyword_file in keyword_files:\n",
    "    # Read keyword file\n",
    "    keyword_df = pd.read_excel(keyword_file)\n",
    "    \n",
    "    # Clean the Keyword column in keyword_df\n",
    "    keyword_df['Keyword'] = keyword_df['Keyword'].apply(clean_text)\n",
    "\n",
    "    # Convert columns to lowercase for case-insensitive comparison\n",
    "    keyword_df['Keyword'] = keyword_df['Keyword'].str.lower()\n",
    "    locations_df['Location'] = locations_df['Location'].str.lower()\n",
    "\n",
    "    # Dictionary to store matched locations\n",
    "    matched_locations_dict = {}\n",
    "\n",
    "    # Iterate through each keyword\n",
    "    for keyword in keyword_df['Keyword']:\n",
    "        # Use fuzzywuzzy process to find the best match\n",
    "        match, score, index = process.extractOne(keyword, locations_df['Location'])\n",
    "        \n",
    "        # Check if the match meets the threshold\n",
    "        if score >= threshold:\n",
    "            # Store the matched location\n",
    "            matched_locations_dict[keyword] = match\n",
    "\n",
    "    # Calculate the percentage of locations in each keyword file\n",
    "    percentage = (len(matched_locations_dict) / len(keyword_df)) * 100\n",
    "\n",
    "    # Store findings in the dictionary\n",
    "    findings[keyword_file] = {\n",
    "        'Total Keywords': len(keyword_df),\n",
    "        'Locations Matched': len(matched_locations_dict),\n",
    "        'Percentage Match': percentage,\n",
    "        'Matched Locations': matched_locations_dict\n",
    "    }\n",
    "\n",
    "# Print the findings\n",
    "for keyword_file, result in findings.items():\n",
    "    print(f'Findings for {keyword_file}:')\n",
    "    print(f'Total Keywords: {result[\"Total Keywords\"]}')\n",
    "    print(f'Locations Matched: {result[\"Locations Matched\"]}')\n",
    "    print(f'Percentage Match: {result[\"Percentage Match\"]:.2f}%')\n",
    "    print(f'Matched Locations: {result[\"Matched Locations\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d5020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
