{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a262698b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to clean locations\n",
    "def clean_location(location):\n",
    "    # Remove leading and trailing whitespaces\n",
    "    location = location.strip()\n",
    "\n",
    "    # Remove special characters\n",
    "    location = re.sub(r'[^a-zA-Z\\s]', '', location)\n",
    "\n",
    "    # Remove numbers\n",
    "    location = re.sub(r'\\d', '', location)\n",
    "\n",
    "    return location\n",
    "\n",
    "# Read Excel file\n",
    "file_path = 'locations.xlsx'\n",
    "df = pd.read_excel(file_path, header=None, names=['Location'])\n",
    "\n",
    "# Clean locations column\n",
    "df['Location'] = df['Location'].apply(clean_location)\n",
    "\n",
    "# Remove rows where 'et al.' exists alone or as part of a phrase\n",
    "df = df[~df['Location'].str.contains(r'\\b(et al\\.|et al)\\b', case=False, regex=True)]\n",
    "\n",
    "# Remove rows where the cleaned 'Location' starts with 'doi'\n",
    "df = df[~df['Location'].str.lower().str.startswith('doi')]\n",
    "\n",
    "# Remove duplicate rows\n",
    "df.drop_duplicates(subset=['Location'], keep='first', inplace=True)\n",
    "\n",
    "# Save cleaned data to a new Excel file\n",
    "output_file_path = 'locations_cleaned.xlsx'\n",
    "df.to_excel(output_file_path, index=False, header=True)\n",
    "\n",
    "print(f'Data cleaned and saved to {output_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469283cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Excel file\n",
    "file_path = 'locations.xlsx'\n",
    "df = pd.read_excel(file_path, header=None, names=['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Location'] = df['Location'].str.lower()\n",
    "df.drop_duplicates(subset=['Location'], keep='first', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d23216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data to a new Excel file\n",
    "output_file_path = 'locations_cleaned.xlsx'\n",
    "df.to_excel(output_file_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b826fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df383085",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read cleaned locations file\n",
    "locations_df = pd.read_excel('locations_cleaned.xlsx', header=None, names=['Location'])\n",
    "\n",
    "# List of other Excel files\n",
    "keyword_files = ['Keyphrases_aws.xlsx', 'Keyphrases_tf-idf.xlsx', 'Keyphrases_yake.xlsx']\n",
    "\n",
    "# Dictionary to store findings\n",
    "findings = {}\n",
    "\n",
    "# Iterate through each keyword file\n",
    "for keyword_file in keyword_files:\n",
    "    # Read keyword file\n",
    "    keyword_df = pd.read_excel(keyword_file)\n",
    "\n",
    "    # Convert columns to lowercase for case-insensitive comparison\n",
    "    keyword_df['Keyword'] = keyword_df['Keyword'].str.lower()\n",
    "    locations_df['Location'] = locations_df['Location'].str.lower()\n",
    "\n",
    "    # Merge the cleaned locations with the keywords on 'Location'\n",
    "    merged_df = pd.merge(keyword_df, locations_df, how='inner', left_on='Keyword', right_on='Location')\n",
    "\n",
    "    # Extract matched locations\n",
    "    matched_locations = merged_df['Location'].tolist()\n",
    "\n",
    "    # Calculate the percentage of locations in each keyword file\n",
    "    percentage = (len(matched_locations) / len(keyword_df)) * 100\n",
    "\n",
    "    # Store findings in the dictionary\n",
    "    findings[keyword_file] = {\n",
    "        'Total Keywords': len(keyword_df),\n",
    "        'Locations Matched': len(matched_locations),\n",
    "        'Percentage Match': percentage,\n",
    "        'Matched Locations': matched_locations\n",
    "    }\n",
    "\n",
    "# Print the findings\n",
    "for keyword_file, result in findings.items():\n",
    "    print(f'Findings for {keyword_file}:')\n",
    "    print(f'Total Keywords: {result[\"Total Keywords\"]}')\n",
    "    print(f'Locations Matched: {result[\"Locations Matched\"]}')\n",
    "    print(f'Percentage Match: {result[\"Percentage Match\"]:.2f}%')\n",
    "    print(f'Matched Locations: {result[\"Matched Locations\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40e3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuzzy all\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Read cleaned locations file\n",
    "locations_df = pd.read_excel('locations_cleaned.xlsx', header=None, names=['Location'])\n",
    "\n",
    "# List of other Excel files\n",
    "keyword_files = ['Keyphrases_aws.xlsx', 'Keyphrases_tf-idf.xlsx', 'Keyphrases_yake.xlsx']\n",
    "\n",
    "# Dictionary to store findings\n",
    "findings = {}\n",
    "\n",
    "# Fuzzy matching threshold (adjust as needed)\n",
    "threshold = 95\n",
    "\n",
    "# Iterate through each keyword file\n",
    "for keyword_file in keyword_files:\n",
    "    # Read keyword file\n",
    "    keyword_df = pd.read_excel(keyword_file)\n",
    "\n",
    "    # Convert columns to lowercase for case-insensitive comparison\n",
    "    keyword_df['Keyword'] = keyword_df['Keyword'].str.lower()\n",
    "    locations_df['Location'] = locations_df['Location'].str.lower()\n",
    "\n",
    "    # Dictionary to store matched locations\n",
    "    matched_locations_dict = {}\n",
    "\n",
    "    # Iterate through each keyword\n",
    "    for keyword in keyword_df['Keyword']:\n",
    "        # Use fuzzywuzzy process to find the best match\n",
    "        match, score, index = process.extractOne(keyword, locations_df['Location'])\n",
    "        \n",
    "        # Check if the match meets the threshold\n",
    "        if score >= threshold:\n",
    "            # Store the matched location\n",
    "            matched_locations_dict[keyword] = match\n",
    "\n",
    "    # Calculate the percentage of locations in each keyword file\n",
    "    percentage = (len(matched_locations_dict) / len(keyword_df)) * 100\n",
    "\n",
    "    # Store findings in the dictionary\n",
    "    findings[keyword_file] = {\n",
    "        'Total Keywords': len(keyword_df),\n",
    "        'Locations Matched': len(matched_locations_dict),\n",
    "        'Percentage Match': percentage,\n",
    "        'Matched Locations': matched_locations_dict\n",
    "    }\n",
    "\n",
    "# Print the findings\n",
    "for keyword_file, result in findings.items():\n",
    "    print(f'Findings for {keyword_file}:')\n",
    "    print(f'Total Keywords: {result[\"Total Keywords\"]}')\n",
    "    print(f'Locations Matched: {result[\"Locations Matched\"]}')\n",
    "    print(f'Percentage Match: {result[\"Percentage Match\"]:.2f}%')\n",
    "    print(f'Matched Locations: {result[\"Matched Locations\"]}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5b5b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Read cleaned locations file\n",
    "locations_df = pd.read_excel('locations_cleaned.xlsx', header=None, names=['Location'])\n",
    "\n",
    "# List of other Excel files\n",
    "keyword_files = ['Keyphrases_aws.xlsx', 'Keyphrases_td-idf.xlsx', 'Keyphrases_yake.xlsx']\n",
    "\n",
    "# Dictionary to store findings\n",
    "findings = {}\n",
    "\n",
    "# Fuzzy matching threshold (adjust as needed)\n",
    "threshold = 90\n",
    "\n",
    "# Iterate through each keyword file\n",
    "for keyword_file in keyword_files:\n",
    "    # Read keyword file\n",
    "    keyword_df = pd.read_excel(keyword_file)\n",
    "\n",
    "    # Convert columns to lowercase for case-insensitive comparison\n",
    "    keyword_df['Keyword'] = keyword_df['Keyword'].str.lower()\n",
    "    locations_df['Location'] = locations_df['Location'].str.lower()\n",
    "\n",
    "    # Dictionary to store matched locations\n",
    "    matched_locations_dict = {}\n",
    "\n",
    "    # Iterate through each keyword\n",
    "    for keyword in keyword_df['Keyword']:\n",
    "        # Use fuzzywuzzy process to find the best match\n",
    "        match = process.extractOne(keyword, locations_df['Location'])\n",
    "        \n",
    "        # Check if the match meets the threshold\n",
    "        if match[1] >= threshold:\n",
    "            # Store the matched location\n",
    "            matched_locations_dict[keyword] = match[0]\n",
    "\n",
    "    # Calculate the percentage of locations in each keyword file\n",
    "    percentage = (len(matched_locations_dict) / len(keyword_df)) * 100\n",
    "\n",
    "    # Store findings in the dictionary\n",
    "    findings[keyword_file] = {\n",
    "        'Total Keywords': len(keyword_df),\n",
    "        'Locations Matched': len(matched_locations_dict),\n",
    "        'Percentage Match': percentage,\n",
    "        'Matched Locations': matched_locations_dict\n",
    "    }\n",
    "\n",
    "# Print the findings\n",
    "for keyword_file, result in findings.items():\n",
    "    print(f'Findings for {keyword_file}:')\n",
    "    print(f'Total Keywords: {result[\"Total Keywords\"]}')\n",
    "    print(f'Locations Matched: {result[\"Locations Matched\"]}')\n",
    "    print(f'Percentage Match: {result[\"Percentage Match\"]:.2f}%')\n",
    "    print(f'Matched Locations: {result[\"Matched Locations\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b8316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove spaces, special characters, numbers, commas, points, etc.\n",
    "    cleaned_text = re.sub(r'[^a-zA-Z]', '', str(text))\n",
    "    return cleaned_text\n",
    "\n",
    "# Read cleaned locations file\n",
    "locations_df = pd.read_excel('locations_cleaned.xlsx', header=None, names=['Location'])\n",
    "locations_df['Location'] = locations_df['Location'].apply(clean_text)\n",
    "\n",
    "# List of other Excel files\n",
    "keyword_files = ['Keyphrases_aws.xlsx', 'Keyphrases_td-idf.xlsx', 'Keyphrases_yake.xlsx']\n",
    "\n",
    "# Dictionary to store findings\n",
    "findings = {}\n",
    "\n",
    "# Fuzzy matching threshold (adjust as needed)\n",
    "threshold = 92\n",
    "\n",
    "# Iterate through each keyword file\n",
    "for keyword_file in keyword_files:\n",
    "    # Read keyword file\n",
    "    keyword_df = pd.read_excel(keyword_file)\n",
    "    \n",
    "    # Clean the Keyword column in keyword_df\n",
    "    keyword_df['Keyword'] = keyword_df['Keyword'].apply(clean_text)\n",
    "\n",
    "    # Convert columns to lowercase for case-insensitive comparison\n",
    "    keyword_df['Keyword'] = keyword_df['Keyword'].str.lower()\n",
    "    locations_df['Location'] = locations_df['Location'].str.lower()\n",
    "\n",
    "    # Dictionary to store matched locations\n",
    "    matched_locations_dict = {}\n",
    "\n",
    "    # Iterate through each keyword\n",
    "    for keyword in keyword_df['Keyword']:\n",
    "        # Use fuzzywuzzy process to find the best match\n",
    "        match, score, index = process.extractOne(keyword, locations_df['Location'])\n",
    "        \n",
    "        # Check if the match meets the threshold\n",
    "        if score >= threshold:\n",
    "            # Store the matched location\n",
    "            matched_locations_dict[keyword] = match\n",
    "\n",
    "    # Calculate the percentage of locations in each keyword file\n",
    "    percentage = (len(matched_locations_dict) / len(keyword_df)) * 100\n",
    "\n",
    "    # Store findings in the dictionary\n",
    "    findings[keyword_file] = {\n",
    "        'Total Keywords': len(keyword_df),\n",
    "        'Locations Matched': len(matched_locations_dict),\n",
    "        'Percentage Match': percentage,\n",
    "        'Matched Locations': matched_locations_dict\n",
    "    }\n",
    "\n",
    "# Print the findings\n",
    "for keyword_file, result in findings.items():\n",
    "    print(f'Findings for {keyword_file}:')\n",
    "    print(f'Total Keywords: {result[\"Total Keywords\"]}')\n",
    "    print(f'Locations Matched: {result[\"Locations Matched\"]}')\n",
    "    print(f'Percentage Match: {result[\"Percentage Match\"]:.2f}%')\n",
    "    print(f'Matched Locations: {result[\"Matched Locations\"]}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60d5020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
