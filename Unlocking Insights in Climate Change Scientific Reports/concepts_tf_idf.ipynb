{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c793fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\e.katsadaki\\Desktop\\test_climate\\IPCC_AR6_WGII_Chapter16.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1bcb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Drop 8 columns using the drop() method\n",
    "df = df.drop(['Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9'], axis=1)\n",
    "\n",
    "# Rename one column using the rename() method\n",
    "df = df.rename(columns={'Unnamed: 0': 'text'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57d8204",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e568bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stopwords and other words to remove\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "common_words = set(['and', 'as', 'or', 'that', 'he', 'she','be','they','them','yes','no','that', 'there','very','are', 'is'])\n",
    "#remove_words = stop_words.union(common_words)\n",
    "\n",
    "# Remove stopwords and other words from the input text\n",
    "def preprocess_text(text):\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenize the text\n",
    "    tokens = text.split()\n",
    "    # Remove stopwords and common words\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in common_words]\n",
    "    # Join the filtered tokens back into a string\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "df['text'] = df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82832965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace('\\d+', '') # remove numbers\n",
    "df['text'] = df['text'].str.replace(r'\\b(?:and|he|she|that|as|or|yes|no|be|by|in|into|as|there|are|is|very|they|the)\\b\\s*', '') # remove stop words and other unwanted words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26958447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract concepts from the input file\n",
    "count_vect = CountVectorizer(ngram_range=(2, 3)) # extract 2-3 word concepts\n",
    "X_train_counts = count_vect.fit_transform(df['text'])\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "feature_names = count_vect.get_feature_names()\n",
    "sum_tfidf = X_train_tfidf.sum(axis=0)\n",
    "sum_tfidf_list = [(feature_names[i], sum_tfidf[0,i]) for i in range(sum_tfidf.shape[1])]\n",
    "sorted_tfidf_list = sorted(sum_tfidf_list, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bce62d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the text into a bag of words\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df['text'])\n",
    "\n",
    "# Convert the bag of words into TF-IDF representation\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "# Sum the TF-IDF scores for each feature across all documents\n",
    "sum_tfidf = X_train_tfidf.sum(axis=0)\n",
    "\n",
    "# Convert the sums into a list of tuples, where each tuple contains a feature name and its sum\n",
    "sum_tfidf_list = [(feature_names[i], sum_tfidf[0,i]) for i in range(sum_tfidf.shape[1])]\n",
    "\n",
    "# Sort the list of tuples by the second element in descending order\n",
    "sorted_tfidf_list = sorted(sum_tfidf_list, key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a0adf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sorted list of tuples into a dataframe\n",
    "df_concepts = pd.DataFrame(sorted_tfidf_list, columns=['Concept', 'Importance'])\n",
    "\n",
    "# Save the dataframe to an Excel file\n",
    "df_concepts.to_excel(r'C:\\Users\\e.katsadaki\\Desktop\\test_climate\\concepts_tf_idf.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595cbba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
